{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7939f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import django\n",
    "\n",
    "# The following lines are here to avoid `SynchronousOnlyOperation` exception\n",
    "os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "django.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9edb9e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16826"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from articles.models import Article\n",
    "\n",
    "cnt = Article.objects.count()\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a7b7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Proof of concept class\n",
    "\n",
    "class ArticleNERWriter:\n",
    "    def __init__(self, article):\n",
    "        self.file_name = self.__get_file_name_from_url(article.article_url)\n",
    "        self.docs = spacy_nlp(article.text)\n",
    "    \n",
    "    def __get_file_name_from_url(self, url):\n",
    "        \"\"\"\n",
    "        url: https://ky.kloop.asia/2011/05/03/osh-shaarynda-birinchi-zholu-mektep-okuuchularynyn-arasynda-mektep-perisi-2011-synak-tk-z-ld/\n",
    "        \"\"\"\n",
    "        split_res = url.split('/')\n",
    "        # for a case if URL ends without /\n",
    "        if split_res[-1]:\n",
    "            pref = split_res[-1]\n",
    "        # if URL ends with / then use the second item from the end\n",
    "        else:\n",
    "            pref = split_res[-2]\n",
    "        return f'{pref}.csv'\n",
    "    \n",
    "    def write_sentence_level_ner_to_file(self):\n",
    "        with open(self.file_name, mode='w') as ner_file:\n",
    "            writer = csv.writer(ner_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            for sent in self.docs.sents:\n",
    "                text = sent.text.strip()\n",
    "                if text:\n",
    "                    ner_results = hf_nlp(text)\n",
    "                    if ner_results:\n",
    "                        writer.writerow([text, *ner_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf130d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muratjumashev/projects/kloop-corpus/env/lib/python3.9/site-packages/transformers/pipelines/token_classification.py:135: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x11c8942c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "from spacy.lang.ky import Kyrgyz\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Davlan/xlm-roberta-base-ner-hrl\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Davlan/xlm-roberta-base-ner-hrl\")\n",
    "hf_nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, grouped_entities=True)\n",
    "\n",
    "spacy_nlp = Kyrgyz()\n",
    "spacy_nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a16a53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "art = Article.objects.first()\n",
    "doc = spacy_nlp(art.text)\n",
    "\n",
    "ner_raw = []\n",
    "\n",
    "for sent in doc.sents:\n",
    "    text = sent.text.strip()\n",
    "    if text:\n",
    "        st = doc.text.find(text)\n",
    "        en = st + len(text) + 1\n",
    "        ner_results = hf_nlp(text)\n",
    "        if ner_results:\n",
    "            ner_d = {\n",
    "                'sentence_start': st,\n",
    "                'sentence_end': en,\n",
    "                'NER': ner_results\n",
    "            }\n",
    "            ner_raw.append(ner_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b6de358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–ê–≤—Ç–æ—Ä–ª–æ—Ä: –ë–µ–∫–∂–∞–Ω –î–∂—É—Å—É–ø–æ–≤, –ê—Ä–∏–µ—Ç –¢—É—Ä–∞—Ç–±–µ–∫–æ–≤\\n–°“Ø—Ä”©—Ç—Ç“Ø–Ω –∞–≤—Ç–æ—Ä—É: –ê—Å–∫–∞—Ç–±–µ–∫ —É—É–ª—É –ò–±—Ä–∞–≥–∏–º\\n–†–µ–¥–∞–∫—Ç–æ—Ä: –ê–π–∑–∞—Ç –®–∞–∫–∏–µ–≤–∞\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text[3028:3135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6082b1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence_start': 3028,\n",
       " 'sentence_end': 3135,\n",
       " 'NER': [{'entity_group': 'PER',\n",
       "   'score': 0.9997777,\n",
       "   'word': '–ë–µ–∫–∂–∞–Ω –î–∂—É—Å—É–ø–æ–≤',\n",
       "   'start': 9,\n",
       "   'end': 25},\n",
       "  {'entity_group': 'PER',\n",
       "   'score': 0.99878484,\n",
       "   'word': '–ê—Ä–∏–µ—Ç –¢—É—Ä–∞—Ç–±–µ–∫–æ–≤',\n",
       "   'start': 26,\n",
       "   'end': 43},\n",
       "  {'entity_group': 'PER',\n",
       "   'score': 0.9997801,\n",
       "   'word': '–ê—Å–∫–∞—Ç–±–µ–∫ —É—É–ª—É –ò–±—Ä–∞–≥–∏–º',\n",
       "   'start': 60,\n",
       "   'end': 82},\n",
       "  {'entity_group': 'PER',\n",
       "   'score': 0.9997498,\n",
       "   'word': '–ê–π–∑–∞—Ç –®–∞–∫–∏–µ–≤–∞',\n",
       "   'start': 92,\n",
       "   'end': 106}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_raw[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f689cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            # üëáÔ∏è alternatively use str()\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dc39b9",
   "metadata": {},
   "source": [
    "## Loop through all articles and write their NERs to ArticleNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "102fb536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, we'll only try to write the first article's contents\n",
    "\n",
    "for art in [Article.objects.first()]:\n",
    "    doc = spacy_nlp(art.text)\n",
    "    ner_raw = []\n",
    "    for sent in doc.sents:\n",
    "        text = sent.text.strip()\n",
    "        if text:\n",
    "            st = doc.text.find(text)\n",
    "            en = st + len(text) + 1\n",
    "            ner_results = hf_nlp(text)\n",
    "            if ner_results:\n",
    "                ner_d = {\n",
    "                    'sentence_start': st,\n",
    "                    'sentence_end': en,\n",
    "                    'NER': ner_results\n",
    "                }\n",
    "                ner_raw.append(ner_d)\n",
    "    ArticleNER.objects.create(article=art, ner_raw=json.dumps(ner_raw, cls=NpEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d1549c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
